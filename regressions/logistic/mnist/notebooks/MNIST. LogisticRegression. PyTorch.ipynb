{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73dfeeae",
   "metadata": {},
   "source": [
    "```python\n",
    "# Uncomment and run the commands below if imports fail\n",
    "# !conda install numpy pytorch torchvision cpuonly -c pytorch -y\n",
    "# !pip install matplotlib --upgrade --quiet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90108855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install torchvision cpuonly -c pytorch -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f05d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66611c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training dataset\n",
    "dataset = MNIST(root='data/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd240f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the size of the dataset\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca70369f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load an additonal test set of 10,000 images.\n",
    "test_dataset = MNIST(root='data/', train=False)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b1c1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x155B96248B0>, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33f3201",
   "metadata": {},
   "source": [
    "Let's look at an example of element from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8e294a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANb0lEQVR4nO3df6gd9ZnH8c9ntVE0kSRK9GL91aioKCZrFMW6uJaUrCixYNcGWVxWuPmjShUhGyoYYVPQXeNKEAsparNLN6UQQ6WsNBLCuv5TEjWrMbFNNsT0JiHBDVrrP9H47B93Itfknjk3Z2bOnHuf9wsu55x5zsw8HPLJzDnz4+uIEICp7y/abgBAfxB2IAnCDiRB2IEkCDuQxOn9XJltfvoHGhYRHm96pS277UW2f297t+3lVZYFoFnu9Ti77dMk/UHSQkkjkrZIWhIRO0rmYcsONKyJLftNknZHxJ6IOCrpl5IWV1gegAZVCfuFkv445vVIMe1rbA/b3mp7a4V1Aaioyg904+0qnLSbHhFrJK2R2I0H2lRlyz4i6aIxr78p6UC1dgA0pUrYt0i6wvZltqdJ+oGkV+tpC0Ddet6Nj4gvbD8k6beSTpP0UkS8X1tnAGrV86G3nlbGd3agcY2cVANg8iDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIm+DtmMZlxzzTUda3fddVfpvMPDw6X1LVu2lNbfeeed0nqZ5557rrR+9OjRnpeNk7FlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGMV1Eli6dGlp/ZlnnulYmz59et3t1OaOO+4orW/evLlPnUwtnUZxrXRSje29kj6VdEzSFxGxoMryADSnjjPo/joiPqphOQAaxHd2IImqYQ9JG22/ZXvck6xtD9veantrxXUBqKDqbvytEXHA9hxJr9v+ICLeGPuGiFgjaY3ED3RAmypt2SPiQPF4WNIGSTfV0RSA+vUcdttn255x/Lmk70raXldjAOrV83F229/S6NZcGv068B8R8ZMu87Ab34PZs2eX1nfu3NmxNmfOnLrbqc3HH39cWr/vvvtK6xs3bqyxm6mj9uPsEbFH0vU9dwSgrzj0BiRB2IEkCDuQBGEHkiDsQBLcSnoSOHLkSGl9xYoVHWurVq0qnfess84qre/bt6+0fvHFF5fWy8ycObO0vmjRotI6h95ODVt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCW0lPcdu2bSutX399+YWL27eX36Lg2muvPdWWJmzu3Lml9T179jS27sms0yWubNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAmuZ5/iVq5cWVp//PHHS+vz5s2rsZtTM23atNbWPRWxZQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJLiePbkLLrigtN7t3uzXXXddne18zfr160vr9957b2Prnsx6vp7d9ku2D9vePmbabNuv295VPM6qs1kA9ZvIbvzPJZ04NMdySZsi4gpJm4rXAAZY17BHxBuSThx/aLGktcXztZLuqbctAHXr9dz48yPioCRFxEHbczq90fawpOEe1wOgJo1fCBMRayStkfiBDmhTr4feDtkekqTi8XB9LQFoQq9hf1XSA8XzByT9up52ADSl62687XWSbpd0nu0RSSskPSXpV7YflLRP0vebbBK9u//++0vr3e4b3+R94bt58803W1v3VNQ17BGxpEPpOzX3AqBBnC4LJEHYgSQIO5AEYQeSIOxAElziOglcddVVpfUNGzZ0rF1++eWl855++uDeTZwhm3vDkM1AcoQdSIKwA0kQdiAJwg4kQdiBJAg7kMTgHmTFV66++urS+mWXXdaxNsjH0bt59NFHS+sPP/xwnzqZGtiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASk/cgbCJl16tL0rJlyzrWnn766dJ5zzzzzJ566oehoaG2W5hS2LIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBIcZ58CVq9e3bG2a9eu0nlnzpxZad3drpd//vnnO9bOOeecSuvGqem6Zbf9ku3DtrePmfak7f22txV/dzbbJoCqJrIb/3NJi8aZ/q8RMa/4+8962wJQt65hj4g3JB3pQy8AGlTlB7qHbL9b7ObP6vQm28O2t9reWmFdACrqNew/lTRX0jxJByWt6vTGiFgTEQsiYkGP6wJQg57CHhGHIuJYRHwp6WeSbqq3LQB16ynstsdee/g9Sds7vRfAYOh6nN32Okm3SzrP9oikFZJutz1PUkjaK2lpcy2iitdee63R5dvjDgX+lbLx4Z944onSeefNm1dav+SSS0rrH374YWk9m65hj4gl40x+sYFeADSI02WBJAg7kARhB5Ig7EAShB1IgktcUcm0adNK690Or5X5/PPPS+vHjh3redkZsWUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4zo5KVq5c2diyX3yx/OLKkZGRxtY9FbFlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkHBH9W5ndv5XV7Nxzz+1Ye/nll0vnXbduXaV6m4aGhkrrH3zwQWm9yrDMc+fOLa3v2bOn52VPZREx7v292bIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJczz5Bq1ev7li7++67S+e98sorS+sHDhwore/fv7+0vnv37o61G264oXTebr0tW7astF7lOPqqVatK690+F5yarlt22xfZ3mx7p+33bf+omD7b9uu2dxWPs5pvF0CvJrIb/4WkxyLiakk3S/qh7WskLZe0KSKukLSpeA1gQHUNe0QcjIi3i+efStop6UJJiyWtLd62VtI9DfUIoAan9J3d9qWS5kv6naTzI+KgNPofgu05HeYZljRcsU8AFU047LanS1ov6ZGI+JM97rn2J4mINZLWFMuYtBfCAJPdhA692f6GRoP+i4h4pZh8yPZQUR+SdLiZFgHUoeslrh7dhK+VdCQiHhkz/V8k/V9EPGV7uaTZEVF6nGYyb9lvvvnmjrVnn322dN5bbrml0rr37t1bWt+xY0fH2m233VY674wZM3pp6Svd/v2UXQJ74403ls772Wef9dRTdp0ucZ3Ibvytkv5O0nu2txXTfizpKUm/sv2gpH2Svl9DnwAa0jXsEfGmpE5f0L9TbzsAmsLpskAShB1IgrADSRB2IAnCDiTBraRr0O1SzbJLUCXphRdeqLOdvjpy5EhpvewW3GgGt5IGkiPsQBKEHUiCsANJEHYgCcIOJEHYgSS4lXQNHnvssdL6GWecUVqfPn16pfXPnz+/Y23JkiWVlv3JJ5+U1hcuXFhp+egftuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATXswNTDNezA8kRdiAJwg4kQdiBJAg7kARhB5Ig7EASXcNu+yLbm23vtP2+7R8V05+0vd/2tuLvzubbBdCrrifV2B6SNBQRb9ueIektSfdI+ltJf46IZya8Mk6qARrX6aSaiYzPflDSweL5p7Z3Srqw3vYANO2UvrPbvlTSfEm/KyY9ZPtd2y/ZntVhnmHbW21vrdYqgComfG687emS/kvSTyLiFdvnS/pIUkj6J43u6v9Dl2WwGw80rNNu/ITCbvsbkn4j6bcR8ew49Usl/SYiru2yHMIONKznC2FsW9KLknaODXrxw91x35O0vWqTAJozkV/jvy3pvyW9J+nLYvKPJS2RNE+ju/F7JS0tfswrWxZbdqBhlXbj60LYgeZxPTuQHGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJrjecrNlHkj4c8/q8YtogGtTeBrUvid56VWdvl3Qq9PV69pNWbm+NiAWtNVBiUHsb1L4keutVv3pjNx5IgrADSbQd9jUtr7/MoPY2qH1J9NarvvTW6nd2AP3T9pYdQJ8QdiCJVsJue5Ht39vebXt5Gz10Ynuv7feKYahbHZ+uGEPvsO3tY6bNtv267V3F47hj7LXU20AM410yzHirn13bw5/3/Tu77dMk/UHSQkkjkrZIWhIRO/raSAe290paEBGtn4Bh+68k/VnSvx0fWsv2P0s6EhFPFf9RzoqIfxyQ3p7UKQ7j3VBvnYYZ/3u1+NnVOfx5L9rYst8kaXdE7ImIo5J+KWlxC30MvIh4Q9KREyYvlrS2eL5Wo/9Y+q5DbwMhIg5GxNvF808lHR9mvNXPrqSvvmgj7BdK+uOY1yMarPHeQ9JG22/ZHm67mXGcf3yYreJxTsv9nKjrMN79dMIw4wPz2fUy/HlVbYR9vKFpBun4360R8ZeS/kbSD4vdVUzMTyXN1egYgAclrWqzmWKY8fWSHomIP7XZy1jj9NWXz62NsI9IumjM629KOtBCH+OKiAPF42FJGzT6tWOQHDo+gm7xeLjlfr4SEYci4lhEfCnpZ2rxsyuGGV8v6RcR8UoxufXPbry++vW5tRH2LZKusH2Z7WmSfiDp1Rb6OInts4sfTmT7bEnf1eANRf2qpAeK5w9I+nWLvXzNoAzj3WmYcbX82bU+/HlE9P1P0p0a/UX+fyU93kYPHfr6lqT/Kf7eb7s3Ses0ulv3uUb3iB6UdK6kTZJ2FY+zB6i3f9fo0N7vajRYQy319m2NfjV8V9K24u/Otj+7kr768rlxuiyQBGfQAUkQdiAJwg4kQdiBJAg7kARhB5Ig7EAS/w+hviHnGhsSdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[10]\n",
    "plt.imshow(image, cmap='gray')\n",
    "print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87a52da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to tensor\n",
    "dataset = MNIST(root='data/', train=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22008615",
   "metadata": {},
   "source": [
    "Check shape of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd9b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 0\n"
     ]
    }
   ],
   "source": [
    "img_tensor, label = dataset[1]\n",
    "print(img_tensor.shape, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48be2a52",
   "metadata": {},
   "source": [
    "Let's look at the tensor it self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30192f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9333, 0.9882, 0.9882, 0.7020, 0.0471],\n",
      "         [0.9922, 0.9137, 0.8157, 0.3294, 0.0000],\n",
      "         [0.9412, 0.2784, 0.0745, 0.1098, 0.0000],\n",
      "         [0.2471, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor[:, 10:15, 10:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb64e67",
   "metadata": {},
   "source": [
    "And max/min values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca9f4bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(img_tensor), torch.min(img_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902edfbe",
   "metadata": {},
   "source": [
    "Plot part of whole image by passing peace of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "487ba7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_tensor[0, 10:15, 10:15], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "642ffcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset of train and validation sets\n",
    "train_ds, val_ds = random_split(dataset, [50000, 10000])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a3ba117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc8d2595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0353,  0.0323, -0.0115,  ...,  0.0018,  0.0050,  0.0056],\n",
       "        [-0.0064,  0.0202,  0.0136,  ..., -0.0049,  0.0300,  0.0160],\n",
       "        [-0.0299, -0.0268, -0.0030,  ..., -0.0296,  0.0173, -0.0267],\n",
       "        ...,\n",
       "        [ 0.0215, -0.0165,  0.0080,  ...,  0.0037, -0.0345, -0.0320],\n",
       "        [-0.0093,  0.0176,  0.0098,  ..., -0.0002,  0.0145, -0.0230],\n",
       "        [ 0.0331, -0.0238, -0.0339,  ..., -0.0129, -0.0320,  0.0177]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "\n",
    "model = nn.Linear(input_size, num_classes)\n",
    "print(model.weight.shape)\n",
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e9e135d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0011,  0.0076, -0.0045, -0.0336, -0.0355,  0.0044, -0.0340, -0.0185,\n",
       "        -0.0113,  0.0030], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.bias.shape)\n",
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec9f173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 7, 7, 7, 5, 6, 8, 3, 6, 9, 9, 9, 3, 8, 2, 5, 1, 6, 0, 3, 5, 2, 2,\n",
      "        9, 9, 8, 7, 0, 5, 8, 4, 3, 6, 9, 2, 1, 5, 9, 4, 1, 5, 7, 7, 7, 7, 5, 7,\n",
      "        9, 4, 3, 7, 1, 5, 8, 8, 4, 9, 1, 4, 8, 6, 0, 1, 7, 6, 6, 9, 2, 0, 3, 3,\n",
      "        8, 1, 3, 4, 7, 2, 3, 3, 9, 6, 6, 3, 7, 4, 4, 8, 9, 0, 9, 5, 3, 4, 1, 9,\n",
      "        7, 7, 1, 1, 6, 2, 3, 7, 1, 2, 2, 6, 2, 6, 5, 9, 7, 4, 8, 2, 6, 9, 4, 3,\n",
      "        0, 8, 5, 8, 6, 6, 5, 1])\n",
      "torch.Size([128, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [3584 x 28], m2: [784 x 10] at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-e5c8dddg\\aten\\src\\TH/generic/THTensorMath.cpp:136",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-72eddc737460>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1372\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1373\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [3584 x 28], m2: [784 x 10] at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-e5c8dddg\\aten\\src\\TH/generic/THTensorMath.cpp:136"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78b66480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0125, -0.0335,  0.0316,  ..., -0.0245, -0.0088,  0.0108],\n",
       "         [-0.0226, -0.0061,  0.0032,  ..., -0.0021, -0.0079, -0.0156],\n",
       "         [ 0.0324, -0.0249, -0.0017,  ...,  0.0216,  0.0262,  0.0288],\n",
       "         ...,\n",
       "         [ 0.0249,  0.0236, -0.0169,  ...,  0.0304,  0.0215, -0.0083],\n",
       "         [-0.0013,  0.0237, -0.0110,  ..., -0.0188,  0.0128, -0.0238],\n",
       "         [ 0.0330, -0.0250, -0.0276,  ..., -0.0151, -0.0261, -0.0153]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0339,  0.0047,  0.0338,  0.0176, -0.0134,  0.0276, -0.0349,  0.0020,\n",
       "         -0.0182, -0.0331], requires_grad=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "\n",
    "model = MnistModel()\n",
    "\n",
    "print(model.linear.weight.shape, model.linear.bias.shape)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e2601",
   "metadata": {},
   "source": [
    "New custom model can be used in the exact same way as before. Let's see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "764d1e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.shape:  torch.Size([128, 10])\n",
      "Sample uptputs:\n",
      " tensor([[-0.0056, -0.1974, -0.3899, -0.3113,  0.1943, -0.2079,  0.1335,  0.0008,\n",
      "         -0.1236,  0.0335],\n",
      "        [-0.2186, -0.2254, -0.1377, -0.2104,  0.1156, -0.0358,  0.3162,  0.1360,\n",
      "          0.0913, -0.1107]])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    break\n",
    "    \n",
    "\n",
    "print(\"outputs.shape: \", outputs.shape)\n",
    "print(\"Sample uptputs:\\n\", outputs[:2].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fabd315b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample probabilities:\n",
      " tensor([[0.1068, 0.0881, 0.0727, 0.0787, 0.1304, 0.0872, 0.1227, 0.1075, 0.0949,\n",
      "         0.1110],\n",
      "        [0.0813, 0.0808, 0.0882, 0.0820, 0.1136, 0.0977, 0.1389, 0.1160, 0.1109,\n",
      "         0.0906]])\n",
      "Sum:  1.0\n"
     ]
    }
   ],
   "source": [
    "# def softmax(y):\n",
    "#     exp_sum = torch.sum(torch.exp(y), axis=1)\n",
    "#     return torch.exp(y) / exp_sum.reshape(-1, 1)\n",
    "\n",
    "# test_softmax = softmax(outputs.data)\n",
    "\n",
    "probs = F.softmax(outputs, dim=1)\n",
    "# test_softmax - probs\n",
    "\n",
    "# Look at sample probabilities\n",
    "print(\"Sample probabilities:\\n\", probs[:2].data)\n",
    "\n",
    "# Add up the probabilities of an output row\n",
    "print(\"Sum: \", torch.sum(probs[0]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "663ba929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 6, 7, 7, 6, 6, 6, 7, 7, 9, 6, 7, 7, 0, 7, 7, 9, 6, 4, 9, 6, 4, 1, 4,\n",
      "        0, 7, 2, 4, 6, 3, 9, 4, 6, 6, 6, 0, 4, 6, 6, 4, 6, 7, 1, 7, 4, 1, 6, 6,\n",
      "        6, 0, 6, 6, 7, 4, 7, 4, 7, 6, 7, 0, 7, 6, 0, 7, 0, 6, 0, 0, 0, 6, 7, 6,\n",
      "        7, 6, 0, 2, 6, 8, 6, 4, 0, 7, 6, 7, 7, 6, 7, 7, 7, 7, 7, 7, 4, 7, 2, 4,\n",
      "        6, 6, 6, 4, 7, 8, 4, 6, 7, 7, 6, 0, 7, 6, 7, 4, 0, 7, 7, 4, 9, 6, 7, 6,\n",
      "        7, 6, 6, 6, 3, 6, 6, 7])\n",
      "tensor([0.1304, 0.1389, 0.1299, 0.1363, 0.1425, 0.1201, 0.1248, 0.1362, 0.1218,\n",
      "        0.1203, 0.1253, 0.1274, 0.1350, 0.1245, 0.1250, 0.1406, 0.1332, 0.1290,\n",
      "        0.1137, 0.1339, 0.1419, 0.1266, 0.1303, 0.1290, 0.1206, 0.1272, 0.1169,\n",
      "        0.1434, 0.1206, 0.1219, 0.1286, 0.1476, 0.1223, 0.1442, 0.1232, 0.1598,\n",
      "        0.1304, 0.1497, 0.1263, 0.1321, 0.1515, 0.1179, 0.1354, 0.1464, 0.1384,\n",
      "        0.1108, 0.1090, 0.1379, 0.1290, 0.1250, 0.1188, 0.1277, 0.1365, 0.1194,\n",
      "        0.1224, 0.1369, 0.1242, 0.1304, 0.1150, 0.1547, 0.1295, 0.1264, 0.1263,\n",
      "        0.1359, 0.1500, 0.1435, 0.1347, 0.1228, 0.1433, 0.1197, 0.1695, 0.1446,\n",
      "        0.1373, 0.1213, 0.1159, 0.1225, 0.1417, 0.1152, 0.1414, 0.1197, 0.1096,\n",
      "        0.1177, 0.1233, 0.1345, 0.1369, 0.1182, 0.1443, 0.1375, 0.1389, 0.1350,\n",
      "        0.1268, 0.1452, 0.1433, 0.1985, 0.1370, 0.1122, 0.1220, 0.1472, 0.1552,\n",
      "        0.1481, 0.1441, 0.1204, 0.1294, 0.1408, 0.1675, 0.1560, 0.1187, 0.1334,\n",
      "        0.1296, 0.1325, 0.1364, 0.1420, 0.1290, 0.1347, 0.1284, 0.1292, 0.1121,\n",
      "        0.1407, 0.1134, 0.1234, 0.1228, 0.1300, 0.1236, 0.1204, 0.1141, 0.1395,\n",
      "        0.1202, 0.1497], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "max_probs, preds = torch.max(probs, dim=1)\n",
    "print(preds)\n",
    "print(max_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e7e1f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 7, 9, 4, 7, 7, 3, 6, 4, 9, 8, 9, 6, 8, 4, 4, 6, 3, 1, 5, 4, 3, 0, 9,\n",
       "        1, 2, 1, 2, 7, 3, 5, 5, 9, 9, 7, 8, 5, 4, 4, 0, 4, 6, 0, 6, 3, 5, 1, 5,\n",
       "        2, 0, 1, 7, 7, 1, 7, 0, 8, 7, 1, 8, 2, 5, 1, 4, 8, 4, 5, 8, 8, 9, 9, 8,\n",
       "        0, 4, 1, 2, 8, 4, 8, 8, 5, 4, 3, 4, 1, 7, 4, 8, 2, 8, 2, 9, 0, 6, 5, 1,\n",
       "        7, 0, 8, 0, 6, 8, 0, 7, 9, 6, 9, 8, 5, 3, 6, 5, 1, 8, 9, 8, 3, 9, 1, 4,\n",
       "        3, 5, 0, 5, 3, 3, 3, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50075da",
   "metadata": {},
   "source": [
    "Now it is not a good predicting. It's because was used only random initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd58f231",
   "metadata": {},
   "source": [
    "## Evaluation Metric and Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0174f0d",
   "metadata": {},
   "source": [
    "***Evalution Metric:***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b55b8",
   "metadata": {},
   "source": [
    "I use **accuracy** as mesure how well is prediction. It can be done with softmax function. But I use simplify estimate because it equivalent for my goal (equivalent relation for linear function and exponential function $\\leftrightarrow$ if linear function grows-up, then exponential function grows-up, if linear down, exp down). \n",
    "\n",
    "\n",
    "$\\mathbb{1}$  - indicator-function.\n",
    "\n",
    "$$\\mathbb{1}_i =\\begin{equation}\n",
    "\\left\\{ \n",
    "  \\begin{array}\\\\\n",
    "    1 & \\mbox{if } \\hat{y} = y\\\\\n",
    "    0 & \\mbox{if } \\hat{y} \\neq y\\\\\n",
    "  \\end{array}\n",
    "  \\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$accuracy = \\frac{1}{m}\\sum_{i=1}^{m} \\mathbb{1}_i\n",
    "$$\n",
    "\n",
    "<!-- HIDE\n",
    "$$L =\\begin{equation}\n",
    "\\left\\{ \n",
    "  \\begin{aligned}\n",
    "    1,\\space \\text{ if }\\ \\hat{y} = y\\\\\n",
    "    -x&+8\\,y&   &=&3\\\\\n",
    "  \\end{aligned}\n",
    "  \\right.\n",
    "\\end{equation}\n",
    "$$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89ccf8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d3a2d",
   "metadata": {},
   "source": [
    "Get accuracy of the current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55531f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0625)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(outputs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f896b29",
   "metadata": {},
   "source": [
    "***Loss function:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fc9b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fe1617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3242, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Loss for current betch of data\n",
    "loss = loss_fn(outputs, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaed3e3",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "**Structure:**\n",
    "```python\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    for batch in train_loader:\n",
    "        # Generate predictions\n",
    "        # Calculate loss\n",
    "        # Compute gradients\n",
    "        # Update weights\n",
    "        # Reset gradients\n",
    "\n",
    "    # Validation phase\n",
    "    for batch in val_loader:\n",
    "        # Generate predictions\n",
    "        # Calculate loss\n",
    "        # Calculate metrics (accuracy etc.)\n",
    "    # Calculate average validation loss & metrics\n",
    "\n",
    "    # Log epoch, loss & metrics for inspection\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3337aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine loss\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "        \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, \n",
    "                                                                     result['val_loss'], \n",
    "                                                                     result['val_acc']))\n",
    "        \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "692f557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, bal_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # train \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        # validation\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "503810ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.3128445148468018, 'val_acc': 0.09414556622505188}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0 = evaluate(model, val_loader)\n",
    "result0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "755011a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.9476, val_acc: 0.6044\n",
      "Epoch [1], val_loss: 1.6789, val_acc: 0.7114\n",
      "Epoch [2], val_loss: 1.4781, val_acc: 0.7553\n",
      "Epoch [3], val_loss: 1.3262, val_acc: 0.7801\n",
      "Epoch [4], val_loss: 1.2091, val_acc: 0.7977\n"
     ]
    }
   ],
   "source": [
    "history1 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fc6a40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.1169, val_acc: 0.8084\n",
      "Epoch [1], val_loss: 1.0428, val_acc: 0.8170\n",
      "Epoch [2], val_loss: 0.9821, val_acc: 0.8244\n",
      "Epoch [3], val_loss: 0.9317, val_acc: 0.8281\n",
      "Epoch [4], val_loss: 0.8889, val_acc: 0.8335\n"
     ]
    }
   ],
   "source": [
    "history2 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9611463c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.8523, val_acc: 0.8356\n",
      "Epoch [1], val_loss: 0.8206, val_acc: 0.8387\n",
      "Epoch [2], val_loss: 0.7928, val_acc: 0.8410\n",
      "Epoch [3], val_loss: 0.7683, val_acc: 0.8441\n",
      "Epoch [4], val_loss: 0.7465, val_acc: 0.8474\n"
     ]
    }
   ],
   "source": [
    "history3 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75070d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.7270, val_acc: 0.8497\n",
      "Epoch [1], val_loss: 0.7093, val_acc: 0.8519\n",
      "Epoch [2], val_loss: 0.6934, val_acc: 0.8527\n",
      "Epoch [3], val_loss: 0.6788, val_acc: 0.8544\n",
      "Epoch [4], val_loss: 0.6655, val_acc: 0.8562\n"
     ]
    }
   ],
   "source": [
    "history4 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7a95b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = [result0] + history1 + history2 + history3\n",
    "accuracies = [result['val_acc'] for result in history]\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs. No. of epochs');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
